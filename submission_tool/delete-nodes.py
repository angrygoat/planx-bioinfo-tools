import json
import argparse
import requests
import datetime
import os

CHUNK_SIZE = 20
NUM_ENTITIES = 99999999

# delete_nodes automates the process of deleting nodes from a project. The 'nodes' parameter is a list,
# and the nodes in the list must be ordered from bottom of tree -> top of tree. This ordering is also the
# reverse of the order in which the nodes are originally submitted.
def delete_nodes(nodes, **kwargs):
    api_url = kwargs["api_url"]
    api_credentials = kwargs["api_credentials"]
    project = kwargs["project"]
    dry_run = kwargs.get("dry_run", False)

    # Get needed URLs
    token_url   = api_url + "/user/credentials/cdis/access_token"
    graphql_url = api_url + "/api/v0/submission/graphql/"
    project_url = api_url + "/api/v0/submission/" + project.replace("-", "/", 1) + "/"

    # get keys
    json_data = open(api_credentials).read()
    keys = json.loads(json_data)
    auth = requests.post(token_url, json=keys)

    for node in nodes:

        # Get id from submitter_id
        query_txt = """query Test { %s (first:%s, project_id: "%s") {submitter_id id}}""" % (node, NUM_ENTITIES, project)
        query = {"query": query_txt}
        output = requests.post(graphql_url, headers={"Authorization": "bearer " + auth.json()["access_token"]}, json=query).text
        data = json.loads(output)

        # Remove all entities from one node by chunks
        entities = [entity["id"] for entity in data["data"][node]]
        if len(entities) == 0:
            print("INFO: Node is already empty: '{}' \t({})".format(node, project))

        last = len(entities) - 1
        chunked_entities = []
        total = 0
        for i, entity_id in enumerate(entities):
            chunked_entities.append(entity_id)
            if len(chunked_entities) >= CHUNK_SIZE or i == last:
                url = project_url + "entities/" + ",".join(chunked_entities)

                if dry_run:
                    response = requests.get(url, headers={"Authorization": "bearer " + auth.json()["access_token"]})
                else:
                    response = requests.delete(url, headers={"Authorization": "bearer " + auth.json()["access_token"]})

                if response.status_code == 200:
                    if dry_run:
                        print("DRY RUN: Would have deleted {} entities from node '{}' \t({}) \t({})".format(len(chunked_entities), node, project, api_url))
                    else:
                        print("Deleted {} entities from node '{}' \t({}) \t({})".format(len(chunked_entities), node, project, api_url))
                elif response.status_code == 400:
                    print("ERR: 400-User Error while deleting entities from node '{}' \t({}) \t({})".format(node, project, api_url))
                    print("URL: " + url)
                    print(response.text)
                elif response.status_code == 403:
                    print("ERR: 403-Unauthorized while deleting entities from node '{}' \t({}) \t({})".format(node, project, api_url))
                    print("URL: " + url)
                    print(response.text)
                elif response.status_code == 404:
                    print("ERR: 404-File Not Found while deleting entities from node '{}' \t({}) \t({}).".format(node, project, api_url))
                    print("URL: " + url)
                    print(response.text)
                else:
                    print("ERR while deleting records from node '{}' \t({}) \t({}):".format(node, project, api_url))
                    print("URL: " + url)
                    print(response.text)#
                total += len(chunked_entities)
                chunked_entities = []
                # Every 1000 requests, refresh the auth token (which expires after a certain amount of time.)
                if total % 1000 == 0:
                    auth = requests.post(token_url, json=keys)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="delete meta data")
    parser.add_argument("-a", "--apiurl", required=True, help="data commons url")
    parser.add_argument("-p", "--project", required=True, help="project id for deletion")
    parser.add_argument("-so", "--submission-order-file", required=True, help="path to submission order for this dictionary. The submission order can be generated by https://github.com/uc-cdis/data-simulator")
    parser.add_argument("-k", "--authfile", help="API key file, which can be obtained from the /profile page of the commons", default="credentials.json")
    parser.add_argument("-d", "--dry_run", action="store_true", help="Test the execution of the commands without actually deleting the records. Substitues all DELETE requests with GET requests.")
    args = parser.parse_args()

    # Get the list of nodes from the submission order file, which is expected to be a list of nodes separated by newlines.
    # Then reverse the list of nodes, because we want to delete the nodes in the reverse order in which they were submitted.
    # (This ensures that we delete the tree from bottom to top.)
    print(args.submission_order_file)
    if not os.path.exists(args.submission_order_file):
        print("ERR: Cannot find file " + args.submission_order_file)
    with open(args.submission_order_file) as sofile:
        nodes = [node.strip() for node in sofile.readlines()]
        nodes.reverse()

    delete_nodes(nodes, api_url=args.apiurl, project=args.project, api_credentials=args.authfile, dry_run=args.dry_run)